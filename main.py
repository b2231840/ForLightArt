import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import speech_recognition as sr
import pyttsx3

# ===== ãƒ¢ãƒ‡ãƒ«æº–å‚™ =====
MODEL_NAME = "rinna/japanese-gpt-neox-3.6b-instruction-sft"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)
if torch.cuda.is_available():
    model = model.to("cuda")

# ===== éŸ³å£°åˆæˆæº–å‚™ =====
engine = pyttsx3.init()
for voice in engine.getProperty('voices'):
    if "Japanese" in voice.name or "Haruka" in voice.name:
        engine.setProperty('voice', voice.id)
        break
engine.setProperty('rate', 180)

# ===== éŸ³å£°èªè­˜ =====
def listen():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        print("ğŸ¤ è©±ã—ã‹ã‘ã¦ãã ã•ã„...")
        audio = r.listen(source)
    try:
        text = r.recognize_google(audio, language="ja-JP")
        print("ğŸ‘‚ èªè­˜çµæœ:", text)
    except sr.UnknownValueError:
        text = ""
        print("âš ï¸ èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ")
    return text

# ===== å¿œç­”ç”Ÿæˆ =====
def generate_response(user_input, history, max_new_tokens=60):
    # ä¼šè©±å±¥æ­´ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    prompt = "ä»¥ä¸‹ã¯äººé–“ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰ã¨AIã®ä¼šè©±ã§ã™ã€‚AIã¯çŸ­ãè‡ªç„¶ãªæ—¥æœ¬èªã§ç­”ãˆã¾ã™ã€‚\n\n"
    for turn in history[-3:]:  # ç›´è¿‘3ã‚¿ãƒ¼ãƒ³ã®ã¿ä¿æŒ
        prompt += f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {turn['user']}\nAI: {turn['ai']}\n"
    prompt += f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_input}\nAI:"

    inputs = tokenizer(prompt, return_tensors="pt")
    if torch.cuda.is_available():
        inputs = {k: v.to("cuda") for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            temperature=0.8,
            top_p=0.9,
            do_sample=True,
            repetition_penalty=1.2,
            pad_token_id=tokenizer.eos_token_id,
            eos_token_id=tokenizer.eos_token_id,
        )

    text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    if "AI:" in text:
        text = text.split("AI:")[-1].strip()

    # æ–‡ã‚’è‡ªç„¶ã«æ­¢ã‚ã‚‹
    stop_puncts = ["ã€‚", "ï¼Ÿ", "ï¼"]
    for p in stop_puncts:
        if p in text:
            text = text[: text.index(p) + 1]
            break
    return text

# ===== éŸ³å£°å‡ºåŠ› =====
def speak(text):
    print("ğŸ’¬ AI:", text)
    engine.say(text)
    engine.runAndWait()

# ===== ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ— =====
def main():
    history = []
    while True:
        user_input = listen()
        if not user_input:
            continue
        if user_input in ["çµ‚äº†", "çµ‚ã‚ã‚Š", "ã•ã‚ˆã†ãªã‚‰","ã¾ãŸã­"]:
            speak("ã¯ã„ã€ã¾ãŸãŠè©±ã—ã—ã¾ã—ã‚‡ã†ã€‚")
            break

        response = generate_response(user_input, history)
        speak(response)
        history.append({"user": user_input, "ai": response})

if __name__ == "__main__":
    main()
